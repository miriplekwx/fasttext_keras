{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "curious-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spanish-offense",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clslist = list(set(train['cls_2'].tolist()))\n",
    "len(clslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "physical-workstation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "clsdict = {}\n",
    "num = 0\n",
    "for i in clslist:\n",
    "    clsdict[num] = i\n",
    "    num += 1\n",
    "\n",
    "one_hot_labels = to_categorical(list(clsdict.keys()), num_classes=6)\n",
    "\n",
    "clsdict_inv = dict(zip(clsdict.values(), clsdict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hollow-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['vector_cls'] = None\n",
    "train['vector_cls'] = train['cls_2'].apply(lambda x : one_hot_labels[clsdict_inv[x]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "immune-clear",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\康文轩\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.062 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "from types import MethodType, FunctionType\n",
    "import re\n",
    "jieba.load_userdict(\"newdict.txt\")\n",
    "\n",
    "def clean_txt(raw):\n",
    "    fil = re.compile(r\"[^0-9a-zA-Z\\u4e00-\\u9fa5]+\")\n",
    "    return fil.sub(' ', raw)\n",
    "\n",
    "def seg(sentence, sw, apply=None):\n",
    "    if isinstance(apply, FunctionType) or isinstance(apply, MethodType):\n",
    "        sentence = apply(sentence)\n",
    "    return_list = []\n",
    "    for i in jieba.cut(sentence):\n",
    "        if i.strip() and i not in sw:\n",
    "            return_list.append(str(i))\n",
    "    return return_list\n",
    "\n",
    "def stop_words():\n",
    "    with open('stopwords.txt', 'r', encoding='utf-8') as swf:\n",
    "        return [line.strip() for line in swf]\n",
    "\n",
    "def save2file(dataFrame, sFilePath):\n",
    "    fpOut = open(sFilePath,'w')\n",
    "    \n",
    "    for index, row in dataFrame.iterrows():\n",
    "        if str(row[1]).strip() == \"\":\n",
    "            print(\"Warning：Meet a empty-content record at line:\" + str(index+1))\n",
    "            continue\n",
    "        str_info = str(row[0]) + \" \" + str(row[1]) +\"\\n\"\n",
    "        fpOut.write(str_info)\n",
    "    \n",
    "    fpOut.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "armed-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['name'] = train['name'].apply(lambda x : seg(x, stop_words(), apply=clean_txt))\n",
    "#train_data['name'] = train_data['name'].parallel_apply(lambda x : [i for i in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "interstate-proportion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['兖州', '特曲', '品香', '兖州特曲', '特曲品香']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bigram(l):\n",
    "    newl = l.copy()\n",
    "    #newl = []\n",
    "    for i in range(len(l)-1):\n",
    "        newl.append(l[i]+l[i+1])\n",
    "    return newl\n",
    "bigram(['兖州', '特曲', '品香'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "actual-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['name'] = train['name'].apply(lambda x : bigram(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "informal-snapshot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>面膜</th>\n",
       "      <td>2092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>保湿</th>\n",
       "      <td>2074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>补水</th>\n",
       "      <td>1158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>洁面乳</th>\n",
       "      <td>967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>男士</th>\n",
       "      <td>877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>扑8048</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>扑8049</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>扑8400</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>扑8416</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>龟裂膏</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61537 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cnt\n",
       "word       \n",
       "面膜     2092\n",
       "保湿     2074\n",
       "补水     1158\n",
       "洁面乳     967\n",
       "男士      877\n",
       "...     ...\n",
       "扑8048     1\n",
       "扑8049     1\n",
       "扑8400     1\n",
       "扑8416     1\n",
       "龟裂膏       1\n",
       "\n",
       "[61537 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "all_words = list(chain.from_iterable(train['name']))\n",
    "# 创建分词数据框\n",
    "corpus = pd.DataFrame(all_words, columns=['word'])\n",
    "corpus['cnt'] = 1\n",
    "\n",
    "# 分组统计\n",
    "g = corpus.groupby(['word']).agg({'cnt': 'count'}).sort_values('cnt', ascending=False)\n",
    "\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "blind-soldier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5363"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = g.index[(g['cnt']>4)].tolist()\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "understanding-gabriel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5363\n"
     ]
    }
   ],
   "source": [
    "all_words = list(set(all_words))\n",
    "print(len(all_words))\n",
    "vocab = { j:i+1 for i, j in enumerate(all_words)}\n",
    "vocab[\"unk\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "automatic-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "train['name'] = train['name'].apply(lambda x:[vocab.get(i,0) for i in x])\n",
    "Sens = pad_sequences(train['name'],maxlen=40)\n",
    "labels = np.array(train['vector_cls'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hungry-guidance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 40, 30)            165000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 66        \n",
      "=================================================================\n",
      "Total params: 165,536\n",
      "Trainable params: 165,456\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input,Embedding,LSTM,Dense,Lambda\n",
    "from keras.layers.merge import dot\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalAveragePooling1D,BatchNormalization,Dropout\n",
    "from keras.optimizers import Adam\n",
    "max_features = 5500\n",
    "embedding_dims = 30\n",
    "maxlen = 40\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='selu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='sigmoid'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.01, beta_1=0.9, beta_2=0.999),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "covered-baltimore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.8369 - accuracy: 0.7479 - val_loss: 1.4015 - val_accuracy: 0.7100\n",
      "Epoch 2/10\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.4294 - accuracy: 0.8491 - val_loss: 1.4425 - val_accuracy: 0.7100\n",
      "Epoch 3/10\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.3678 - accuracy: 0.8645 - val_loss: 1.1820 - val_accuracy: 0.7470\n",
      "Epoch 4/10\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.3470 - accuracy: 0.8681 - val_loss: 0.3774 - val_accuracy: 0.8625\n",
      "Epoch 5/10\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.3184 - accuracy: 0.8859 - val_loss: 0.3438 - val_accuracy: 0.8730\n",
      "Epoch 6/10\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.2936 - accuracy: 0.8907 - val_loss: 1.0448 - val_accuracy: 0.7555\n",
      "Epoch 7/10\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.2882 - accuracy: 0.8966 - val_loss: 0.3812 - val_accuracy: 0.8930\n",
      "Epoch 8/10\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.2712 - accuracy: 0.9067 - val_loss: 0.5105 - val_accuracy: 0.8640\n",
      "Epoch 9/10\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.2540 - accuracy: 0.9110 - val_loss: 0.2876 - val_accuracy: 0.9265\n",
      "Epoch 10/10\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.2550 - accuracy: 0.9131 - val_loss: 0.2872 - val_accuracy: 0.9285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cab2701250>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Sens,labels,batch_size=100,epochs=10,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "clean-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat(s):\n",
    "    s = np.expand_dims(s, 1)\n",
    "    l = model.predict(s.T).tolist()[0]\n",
    "    return clsdict[l.index(max(l))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "conservative-rugby",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['name'] = test['name'].apply(lambda x:seg(x, stop_words(), apply=clean_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "incorporated-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['name'] = test['name'].apply(lambda x:bigram(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "looking-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['vec'] = test['name'].apply(lambda x:[vocab.get(i,0) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "executive-symphony",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sens_test = pad_sequences(test['vec'],maxlen=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "resistant-olive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0, 1805, 2712, 1432,    0,  782, 1482,\n",
       "       3265,    0,    0,    0,    0,    0, 5170])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sens_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "heard-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['vec_long'] = None\n",
    "for i,r in test.iterrows():\n",
    "    test.at[i,'vec_long'] = Sens_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "nonprofit-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test['precat'] = test['vec_long'].apply(lambda x:cat(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "mark = 0\n",
    "for i,r in test.iterrows():\n",
    "    if r['cls_2'] == r['precat']:\n",
    "        mark += 1\n",
    "print(mark/10542)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-devil",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
